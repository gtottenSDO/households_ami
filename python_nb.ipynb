{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Data Loading\n",
    "Import required libraries including pandas, numpy, census API wrapper and establish API connections for Census and HUD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from census import Census\n",
    "from us import states\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Establish API connections\n",
    "CENSUS_API_KEY = os.getenv(\"CENSUS_API_KEY\")\n",
    "HUD_API_KEY = os.getenv(\"HUD_API_KEY\")\n",
    "\n",
    "census = Census(CENSUS_API_KEY)\n",
    "\n",
    "# Function to get HUD data\n",
    "def get_hud_data(endpoint, params):\n",
    "    base_url = \"https://www.huduser.gov/hudapi/public/\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HUD_API_KEY}\"}\n",
    "    response = requests.get(f\"{base_url}{endpoint}\", headers=headers, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Example usage of get_hud_data function\n",
    "hud_params = {\"year\": 2023, \"state\": \"CO\"}\n",
    "hud_data = get_hud_data(\"income_limits\", hud_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census API Data Collection\n",
    "Query the Census API using census-api-wrapper to collect Median Family Income data for years 2005-2023, handling the 2020 gap year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years to query\n",
    "acs_years = list(range(2005, 2020)) + list(range(2021, 2024))\n",
    "\n",
    "# Function to get ACS data for a given year\n",
    "def get_acs_data(year):\n",
    "    return census.acs1.state(('B19113_001E'), states.CO.fips, year=year)\n",
    "\n",
    "# Collect ACS data for all years\n",
    "acs_data = []\n",
    "for year in acs_years:\n",
    "    data = get_acs_data(year)\n",
    "    for entry in data:\n",
    "        entry['year'] = year\n",
    "    acs_data.extend(data)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "acs_df = pd.DataFrame(acs_data)\n",
    "\n",
    "# Rename columns for clarity\n",
    "acs_df.rename(columns={'B19113_001E': 'median_family_income'}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "acs_df.to_csv('data/acs_mfi.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "acs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical MFI Data Processing\n",
    "Process historical MFI data from 2000-2004 using pandas to read and transform CSV data to match the API format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process historical MFI data from 2000-2004 using pandas to read and transform CSV data to match the API format\n",
    "\n",
    "# Read the historical MFI data from CSV\n",
    "historical_mfi_df = pd.read_csv(\"MultiYearProfiles0402004.csv\")\n",
    "\n",
    "# Filter the data for \"Median family income (dollars)\" and \"Colorado\"\n",
    "historical_mfi_df = historical_mfi_df[\n",
    "    (historical_mfi_df['Stub'] == \"Median family income (dollars)\") & \n",
    "    (historical_mfi_df['Geographic Name'] == \"Colorado\")\n",
    "]\n",
    "\n",
    "# Select relevant columns and pivot the data to match the API format\n",
    "historical_mfi_df = historical_mfi_df.melt(\n",
    "    id_vars=[\"Geographic Name\"], \n",
    "    value_vars=[col for col in historical_mfi_df.columns if \"Estimate\" in col],\n",
    "    var_name=\"year\", \n",
    "    value_name=\"estimate\"\n",
    ")\n",
    "\n",
    "# Extract the year from the column names\n",
    "historical_mfi_df['year'] = historical_mfi_df['year'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Rename columns to match the API format\n",
    "historical_mfi_df.rename(columns={\"Geographic Name\": \"NAME\", \"estimate\": \"median_family_income\"}, inplace=True)\n",
    "\n",
    "# Append the historical data to the ACS data\n",
    "acs_df = pd.concat([acs_df, historical_mfi_df[['year', 'median_family_income']]], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "acs_df.to_csv('data/acs_mfi_combined.csv', index=False)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "acs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPUMS Data Processing\n",
    "Use ipumspy package to fetch and process PUMS data, including household characteristics and income variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for IPUMS data processing\n",
    "import ipumspy\n",
    "from ipumspy import IpumsApiClient, UsaExtract\n",
    "import duckdb\n",
    "\n",
    "# Initialize IPUMS API client\n",
    "ipums_api_key = os.getenv(\"IPUMS_API_KEY\")\n",
    "client = IpumsApiClient(ipums_api_key)\n",
    "\n",
    "# Define the variables to extract from IPUMS\n",
    "variables = [\n",
    "    \"YEAR\", \"STATEFIP\", \"COUNTYFIP\", \"PUMA\", \"NUMPREC\", \"CPI99\", \"OWNERSHP\", \"OWNCOST\", \n",
    "    \"RENT\", \"HHTYPE\", \"HHINCOME\", \"INCTOT\", \"INCWAGE\", \"INCBUS00\", \"INCSS\", \"INCWELFR\", \n",
    "    \"INCINVST\", \"INCSUPP\", \"INCOTHER\", \"INCEARN\", \"POVERTY\", \"CBPOVERTY\", \"AGE\", \"FAMUNIT\", \n",
    "    \"FAMSIZE\", \"NCHILD\", \"NCHLT5\", \"FTOTINC\", \"BEDROOMS\", \"REPWT\"\n",
    "]\n",
    "\n",
    "# Define the samples to extract (ACS 1-year samples from 2000 to 2023)\n",
    "samples = [f\"us{year}a\" for year in range(2000, 2024)]\n",
    "\n",
    "# Create the extract request\n",
    "extract = UsaExtract(\n",
    "    collection=\"usa\",\n",
    "    description=\"ACS 1 year samples in Colorado of income variables, all samples since 2000\",\n",
    "    samples=samples,\n",
    "    variables=variables\n",
    ")\n",
    "\n",
    "# Submit the extract request and wait for it to complete\n",
    "extract.submit(client)\n",
    "extract.wait_for_extract(client)\n",
    "\n",
    "# Download the extract data\n",
    "extract.download(client, path=\"data/ipums_extract.zip\")\n",
    "\n",
    "# Read the IPUMS data into a DataFrame\n",
    "ipums_data = ipumspy.read_ipums_micro(\"data/ipums_extract.zip\")\n",
    "\n",
    "# Convert the IPUMS data to a DuckDB database for efficient querying\n",
    "duckdb_conn = duckdb.connect(\"data/ipums_data.duckdb\")\n",
    "duckdb_conn.execute(\"CREATE TABLE ipums_data AS SELECT * FROM ipums_data\")\n",
    "\n",
    "# Query the DuckDB database to filter and process the data\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        YEAR, STATEFIP, COUNTYFIP, PUMA, NUMPREC, CPI99, OWNERSHP, OWNCOST, RENT, HHTYPE, \n",
    "        HHINCOME, INCTOT, INCWAGE, INCBUS00, INCSS, INCWELFR, INCINVST, INCSUPP, INCOTHER, \n",
    "        INCEARN, POVERTY, CBPOVERTY, AGE, FAMUNIT, FAMSIZE, NCHILD, NCHLT5, FTOTINC, BEDROOMS, \n",
    "        REPWT,\n",
    "        CASE \n",
    "            WHEN AGE >= 18 THEN NUMPREC - NCHILD \n",
    "            ELSE 0 \n",
    "        END AS nadults,\n",
    "        CASE \n",
    "            WHEN AGE < 18 THEN NUMPREC - nadults \n",
    "            ELSE 0 \n",
    "        END AS nchildren,\n",
    "        CASE \n",
    "            WHEN nadults = 1 AND NCHILD = 0 THEN 'One adult with no children'\n",
    "            WHEN nadults = 1 AND NCHILD > 0 THEN 'One adult with children'\n",
    "            WHEN nadults > 1 AND NCHILD = 0 THEN 'More than one adult with no children'\n",
    "            WHEN nadults > 1 AND NCHILD > 0 THEN 'More than one adult with children'\n",
    "        END AS household_type_description,\n",
    "        CASE \n",
    "            WHEN AGE < 18 THEN 'Under 18'\n",
    "            WHEN AGE BETWEEN 18 AND 24 THEN '18-24'\n",
    "            WHEN AGE BETWEEN 25 AND 44 THEN '25-44'\n",
    "            WHEN AGE BETWEEN 45 AND 64 THEN '45-64'\n",
    "            ELSE '65 and over'\n",
    "        END AS age_group_description\n",
    "    FROM ipums_data\n",
    "\"\"\"\n",
    "\n",
    "processed_ipums_data = duckdb_conn.execute(query).fetch_df()\n",
    "\n",
    "# Save the processed IPUMS data to a CSV file\n",
    "processed_ipums_data.to_csv('data/processed_ipums_data.csv', index=False)\n",
    "\n",
    "# Display the processed IPUMS data\n",
    "processed_ipums_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household Size Adjustments\n",
    "Calculate household size adjustments and create demographic categorizations using pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household Size Adjustments\n",
    "\n",
    "# Calculate household size adjustments and create demographic categorizations\n",
    "\n",
    "# Define the adjustment factor based on household size\n",
    "def calculate_hhadj(hhsize):\n",
    "    if hhsize < 4:\n",
    "        return 1 - (4 - hhsize) * 0.1\n",
    "    elif hhsize > 4:\n",
    "        return 1 + (hhsize - 4) * 0.08\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the adjustment factor to the processed IPUMS data\n",
    "processed_ipums_data['hhadj'] = processed_ipums_data['NUMPREC'].apply(calculate_hhadj)\n",
    "\n",
    "# Merge the ACS median family income data with the processed IPUMS data\n",
    "merged_data = pd.merge(\n",
    "    processed_ipums_data,\n",
    "    acs_df[['year', 'median_family_income']],\n",
    "    left_on='YEAR',\n",
    "    right_on='year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate the adjusted median family income for each household\n",
    "merged_data['mfi_hh'] = merged_data['median_family_income'] * merged_data['hhadj']\n",
    "\n",
    "# Calculate the percentage of median family income for each household\n",
    "merged_data['pct_mfi'] = merged_data['HHINCOME'] / merged_data['mfi_hh']\n",
    "\n",
    "# Define the AMI group based on the percentage of median family income\n",
    "ami_bins = [0, 0.3, 0.5, 0.8, 1, float('inf')]\n",
    "ami_labels = ['0-30', '30-50', '50-80', '80-100', '100+']\n",
    "merged_data['ami_group'] = pd.cut(merged_data['pct_mfi'], bins=ami_bins, labels=ami_labels, right=False)\n",
    "\n",
    "# Define the AMI percentile based on the percentage of median family income\n",
    "merged_data['ami_percentile'] = np.ceil(merged_data['pct_mfi'] * 10) / 10\n",
    "\n",
    "# Calculate housing cost as a percentage of income\n",
    "merged_data['housing_cost_pct'] = np.where(\n",
    "    merged_data['OWNERSHP'] == 2,\n",
    "    merged_data['RENT'] * 12 / merged_data['HHINCOME'],\n",
    "    merged_data['OWNCOST'] * 12 / merged_data['HHINCOME']\n",
    ")\n",
    "\n",
    "# Determine cost burdened status\n",
    "merged_data['cost_burdened_30'] = merged_data['housing_cost_pct'] >= 0.3\n",
    "merged_data['cost_burdened_50'] = merged_data['housing_cost_pct'] >= 0.5\n",
    "\n",
    "# Save the adjusted data to a CSV file\n",
    "merged_data.to_csv('data/adjusted_ipums_data.csv', index=False)\n",
    "\n",
    "# Display the adjusted data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMI Calculations\n",
    "Calculate AMI percentiles, cost burden metrics, and household classifications using numpy and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AMI percentiles, cost burden metrics, and household classifications\n",
    "\n",
    "# Define the adjustment factor based on household size\n",
    "def calculate_hhadj(hhsize):\n",
    "    if hhsize < 4:\n",
    "        return 1 - (4 - hhsize) * 0.1\n",
    "    elif hhsize > 4:\n",
    "        return 1 + (hhsize - 4) * 0.08\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the adjustment factor to the processed IPUMS data\n",
    "processed_ipums_data['hhadj'] = processed_ipums_data['NUMPREC'].apply(calculate_hhadj)\n",
    "\n",
    "# Merge the ACS median family income data with the processed IPUMS data\n",
    "merged_data = pd.merge(\n",
    "    processed_ipums_data,\n",
    "    acs_df[['year', 'median_family_income']],\n",
    "    left_on='YEAR',\n",
    "    right_on='year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate the adjusted median family income for each household\n",
    "merged_data['mfi_hh'] = merged_data['median_family_income'] * merged_data['hhadj']\n",
    "\n",
    "# Calculate the percentage of median family income for each household\n",
    "merged_data['pct_mfi'] = merged_data['HHINCOME'] / merged_data['mfi_hh']\n",
    "\n",
    "# Define the AMI group based on the percentage of median family income\n",
    "ami_bins = [0, 0.3, 0.5, 0.8, 1, float('inf')]\n",
    "ami_labels = ['0-30', '30-50', '50-80', '80-100', '100+']\n",
    "merged_data['ami_group'] = pd.cut(merged_data['pct_mfi'], bins=ami_bins, labels=ami_labels, right=False)\n",
    "\n",
    "# Define the AMI percentile based on the percentage of median family income\n",
    "merged_data['ami_percentile'] = np.ceil(merged_data['pct_mfi'] * 10) / 10\n",
    "\n",
    "# Calculate housing cost as a percentage of income\n",
    "merged_data['housing_cost_pct'] = np.where(\n",
    "    merged_data['OWNERSHP'] == 2,\n",
    "    merged_data['RENT'] * 12 / merged_data['HHINCOME'],\n",
    "    merged_data['OWNCOST'] * 12 / merged_data['HHINCOME']\n",
    ")\n",
    "\n",
    "# Determine cost burdened status\n",
    "merged_data['cost_burdened_30'] = merged_data['housing_cost_pct'] >= 0.3\n",
    "merged_data['cost_burdened_50'] = merged_data['housing_cost_pct'] >= 0.5\n",
    "\n",
    "# Save the adjusted data to a CSV file\n",
    "merged_data.to_csv('data/adjusted_ipums_data.csv', index=False)\n",
    "\n",
    "# Display the adjusted data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export\n",
    "Export processed data to CSV files in various formats for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Export\n",
    "\n",
    "# Export processed data to CSV files in various formats for further analysis\n",
    "\n",
    "# Save the AMI percentiles by year to a CSV file\n",
    "ami_percentile_by_year.to_csv('data/ami_percentile_by_year_long.csv', index=False)\n",
    "\n",
    "# Save the processed IPUMS data to a CSV file\n",
    "processed_ipums_data.to_csv('data/processed_ipums_data.csv', index=False)\n",
    "\n",
    "# Save the adjusted IPUMS data to a CSV file\n",
    "merged_data.to_csv('data/adjusted_ipums_data.csv', index=False)\n",
    "\n",
    "# Convert data to Eviews friendly format\n",
    "ami_percentile_by_year_eviews = ami_percentile_by_year.pivot_table(\n",
    "    index='YEAR', \n",
    "    columns=['ami_group', 'tenure'], \n",
    "    values='total_hh', \n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "# Save the Eviews friendly format data to a CSV file\n",
    "ami_percentile_by_year_eviews.to_csv('data/ami_percentile_by_year_eviews.csv', index=False)\n",
    "\n",
    "# Display the first few rows of each exported DataFrame\n",
    "print(\"AMI Percentile by Year (Long Format):\")\n",
    "print(ami_percentile_by_year.head())\n",
    "\n",
    "print(\"\\nProcessed IPUMS Data:\")\n",
    "print(processed_ipums_data.head())\n",
    "\n",
    "print(\"\\nAdjusted IPUMS Data:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "print(\"\\nAMI Percentile by Year (Eviews Format):\")\n",
    "print(ami_percentile_by_year_eviews.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
